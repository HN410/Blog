{"pages":[{"title":"Not Found","text":"お探しの記事は見つかりませんでした。","link":"/404.html"},{"title":"お勧めの本紹介","text":"管理者が今までに買ってよかったと思った本を紹介するページです． 随時更新予定． 技術書 コンピュータの構成と設計 第5版 上・下 技術書 コンピュータの構成と設計 第5版 上・下 いわゆるパタヘネ．コンピュータのハードウェア部分の構成を詳しく説明した良書です．基礎的なデジタル回路（半加算器，マルチプレクサなど）が分かっていれば，一から原始的なCPUを設計できるレベルに丁寧に書いてあります．","link":"/books.html"},{"title":"お勧めのツール紹介","text":"管理者が便利だと感じたツールの紹介です． 随時更新予定 Latex-OCR Latex-OCR Latexの数式画像からLatex形式のテキストに変換してくれるオープンソースのソフト． Githubのリンク こちらでも紹介しています．","link":"/tools.html"}],"posts":[{"title":"自転車用経路探索ソフトを作ってみた","text":"突然ですが，下のAからBへの最適な経路はどのようなルートが考えられるでしょうか． 最短経路を考えれば下のようになります．多くの経路探索サービスでもほぼ同様なルートが出るでしょう． しかし，このルートを自転車で走ろうとするとどうなるでしょう．国土地理院の地理院地図を見てみましょう． 出典：国土地理院ウェブサイト, 自分で作る色別標高図 実はこのあたり結構高低差が激しいです．しかもさっきのルートは尾根と谷を何度も横断するようなルートとなっており，自転車で通るにはとても厳しいルートとなっています（少なくとも貧弱な私には）． そこで，なるべく傾斜をよけて目的地へ向かうようなルートを検索してくれるソフトウェアを作成しました．そのソフトウェアで出したルートが下のようになっております．地理院地図と見比べていただければ，うまく高低差の激しいルートを避けて最低限の上下で向かえるルートになっていると思います． 使用したライブラリ，データ 大まかな方針 感想 使用したライブラリ，データ OSMnxとFoliumというライブラリを使いました，前者はOpenStreatMapを利用して地理データの操作が行えるライブラリ，後者は地理データの可視化をするためのライブラリです．両者ともに少々インストールが特殊なので，利用する際は以下のサイト等を参考にしていただけるとよいと思います． GeoPandasのインストールに失敗した場合の対処法（Fiona/GDALのエラー + Rtreeのインストール） | USHITORA Lab. また，高低差のデータはOpenStreatMapには登録されていないようで，OSMnxでデータを得るにはGoogleMapsAPIを経由する必要があります．これを使うこともできなくはないのですが，今回の用途ではリクエスト数が膨大になり，とても私には払えない金額になりそうなのでこれは使えません． しかしながら，国土地理院の基盤地図情報サービスで細かな標高データを無料でダウンロードすることができます(登録必要，用途によって別途申請などが必要なので注意)．今回はこちらを使わせていただきます． このような高品質なデータを無料で使わせていただけるのは学生には非常にありがたいサービスです． 大まかな方針 OSMnxに，ox.shortest_path()という，経路グラフ上の最短距離を探索する関数があります．このオプションで各辺のコストを指定することができます．そのため各辺に対して，距離，高低差，勾配の大きさ等に応じた独自のコストを作成して，それで最短経路探索をさせました． 感想 正直最終的に行っていることはそれほど難しいことではなく，一番難しかったのはどの方法で実現するかを考えるところでした．この方法ならここまでできるとわかってもその先の手段が実現的でなかったりその逆だったりというパターンをいくつか踏んで苦労しました．初めてGISデータを取り扱ったこともあり，慣れないデータ形式に少し手間取りましたが，何とか実用的なものを作れました．似たようなものを作りたいという方に，このような方法があるという参考になれば幸いです． また，地理データを扱う際，表現が変わるとデータの整列順序が変わるのが非常に紛らわしかったです．北半球では各地点を直感的に行列上で表そうとすると，行番号が上がるにつれて低緯度方向に移動するので，この方向で表現されているデータと逆方向に整列されたデータがあり，それらを変換する必要があるので少々面倒でした．","link":"/2022/03/27/Python/RoutingForBicycle/"},{"title":"フォントを生成するGANを作った話(前編)","text":"2021 ISer Advent Calendar 19日目の記事です． 記事が長くなりそうでかつ19日が開いていたので，内容を2つに分けてお送りします． 突然ですが，皆さんはこのような経験はありませんか？ おお～．いかしたフォントだな～… なんのフォント使ってるんだろ？ ……… このように，見つけたフォントがなんのフォントか知りたいのにどう検索すればいいのかわからない…． じゃあ，自分で作ればいいじゃない! ということで作られたのがこちらになります． 概要 実装 データ収集，チェック 次回予告と近況 使用させていただいた素材 概要 目的のフォントで描画した画像の組を複数と，変換したい文字を入力することで，その文字を目的のフォントで描画した画像を生成するモデルを訓練するGANを作成しました． 大体こんな感じ 実装 Generator部分について，実際の実装をもう少し細かく見ると以下のようになっており，文字のエンコードをする部分，フォントのエンコードをする部分，それらをもとに画像を生成する部分の3つに分けられます． 大体こんな感じ 文字，フォントのエンコードをする部分ではEfficientNetという画像認識モデル[1]を，生成する部分ではStyleGANという画像生成モデルを用いており，この全体の構成はpixel2style2pixelを基にしています． これらのモデルについての説明は様々なサイトで記事にされているのでそちらに譲ります． また，入力した画像がGeneratorが生成したものか，既存のフォントでレンダリングしたものかを判別するDiscriminatorも，EfficientNetを基にしております． データ収集，チェック ネットワークを作ったところで早速訓練と行きたいところですが，まずはデータの収集とそのチェックがあります．画像に比べれば一枚一枚チェックしなくて言い分楽ですが，それでも検査しなければいけないことは沢山あります． 例えば， 英数字，かな，漢字のうちどれに対応しているか(英数字だけ，かなだけ，ごく一部の文字だけに対応など，いろいろなパターンがある)[2] アルファベットの大文字小文字両方に対応しているか (英数字のみに対応するフォントで，小文字も大文字として表示しているフォントがたまにある) (g, バックスラッシュなど，異なる字体が存在する文字の表記がデータセット内で統一されているか) 等があります． この作業を効率化させるため，ipywidgetsというライブラリを使用しました． 画像のように，JupyterNotebook上でGUIを構築し，操作をすることができるので，ちょっとした作業におすすめです． 実際に作成したGUI 次回予告と近況 次回は訓練についてと(途中)結果について書きます． この記事を公開する数日前にバグが発覚したのと，改善案を思いついたということもあり，現在急いで学習のやり直しをしております． 果たして後編までに間に合うんでしょうか(). 使用させていただいた素材 thinking-face … https://icon-icons.com/icon/thinking-face/110034 GUIのフォント … しろくまフォント 厳密にはこれにmap2styleというpSpのモデルの一部を組み合わせたネットワーク ↩︎ このチェックは自動化できそうに思うかもしれませんが，対応外の文字もレンダリングできてしまう上に，その結果もまちまち（何も表示されなかったり豆腐になったり）なので，実際に目視したほうが早いと思います． ↩︎","link":"/2021/12/19/deepL/20211219/"},{"title":"blenderで境界ぼかしをする","text":"境界をぼかすのは割とメジャーな表現な気がするのにもかかわらず，調べてもやり方があまり出てこなかったので，ノードでのコンポジットの方法をメモしておきます．Blenderのバージョンは2.93.3です． 目標 下準備 コンポジット 完成 (function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a; b[a]=b[a]||function(){arguments.currentScript=c.currentScript ||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)}; c.getElementById(a)||(d=c.createElement(f),d.src=g, d.id=a,e=c.getElementsByTagName(\"body\")[0],e.appendChild(d))}) (window,document,\"script\",\"//dn.msmstatic.com/site/cardlink/bundle.js?20220329\",\"msmaflink\"); msmaflink({\"n\":\"BlenderユーザーのためのPython入門 [ 大西 武 ]\",\"b\":\"\",\"t\":\"\",\"d\":\"https:\\/\\/thumbnail.image.rakuten.co.jp\",\"c_p\":\"\",\"p\":[\"\\/@0_mall\\/book\\/cabinet\\/3546\\/9784863543546.jpg\"],\"u\":{\"u\":\"https:\\/\\/item.rakuten.co.jp\\/book\\/16738013\\/\",\"t\":\"rakuten\",\"r_v\":\"\"},\"v\":\"2.1\",\"b_l\":[{\"id\":1,\"u_tx\":\"楽天市場で見る\",\"u_bc\":\"#f76956\",\"u_url\":\"https:\\/\\/item.rakuten.co.jp\\/book\\/16738013\\/\",\"a_id\":3173811,\"p_id\":54,\"pl_id\":27059,\"pc_id\":54,\"s_n\":\"rakuten\",\"u_so\":1},{\"u_bc\":\"#f79256\",\"u_tx\":\"Amazonで見る\",\"u_url\":\"https:\\/\\/www.amazon.co.jp\\/s\\/ref=nb_sb_noss_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A\\u0026url=search-alias%3Daps\\u0026field-keywords=Blender%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AEPython%E5%85%A5%E9%96%80%20%5B%20%E5%A4%A7%E8%A5%BF%20%E6%AD%A6%20%5D\",\"s_n\":\"amazon\",\"u_so\":2,\"a_id\":3333479,\"p_id\":170,\"pc_id\":185,\"pl_id\":27060,\"id\":2}],\"eid\":\"oRCMU\",\"s\":\"s\"}); リンク 目標 以下のように，平面と球のオブジェクトを用意し，球のうち三次元的な距離が平面に近い部分だけぼかすような表現を目指します．イメージとしては球が平面から湧き出しているような感じですね． 下準備 「Plane」，「Ball」の二つのビューレイヤーを作成し，前者では平面をレンダリング対象に，後者では球をレンダリング対象，平面をマスクの対象にします．以下の図のように設定すればOKです． コンポジット 下準備が済んだところで，コンポジットに入ります．コンポジットエディタを開き，ノードを使用するにチェック，そのあと，ノードを以下のようにつなぎます． Planeのレンダリング結果にBallのそれがアルファオーバーされた，普通の結果が得られます．このBallの画像の下部分をぼかしていきます． レンダーレイヤーの深度は各ピクセルにおける，カメラと対象物の距離を表していますので，この減算結果が小さいほど球と平面が近いことを表しています．そのためその減算結果が一定の範囲内にあるときのみ0より大きい結果を返すようなノードグループを作成します． 新しく適当なノードを追加し，それを選択したうえで追加→グループ→グループ作成でノードグループを作り，以下のように設計します． これは，input1-input2の結果がthresholdより小さくかつ正であるときのみに出力から0以上の値をだし，そうでない時は0を出力するようなノードとなっております．また，後で調整を楽にするために，出力にmultiplierの値を掛けられるようにしております． このノードグループができたら，右上にある曲がった矢印のボタンを押して親ノードツリーに移動し，再度以下のようにノードをつなぎます． 各値はプレビューを見ながら調整してください．ぼかしのXYを調整することでぼかしの効果が大きくなり，さっき作ったノードグループのthresholdを大きくするとぼかしの適用される範囲が広がります． 完成 これにより，めでたく目標としていた画像が合成できます． やはりBlenderの表現力はなかなかですね．","link":"/2022/03/08/blender/BoundaryBlur/"},{"title":"フォントを生成するGANを作った話(後編)","text":"2021 ISer Advent Calendar 23日目の記事です． まだ前回の記事を読んでいない，あるいはもう忘れたという方は前回の記事を読まれることをお勧めします． 訓練１ 訓練2 (途中)結果 感想 備忘録 余談 使用させていただいたフォント 訓練１ さて，ようやく訓練フェーズに入ったわけですが，前述のネットワークをそのまま訓練しようとすると，非常に時間がかかるので，段階的に訓練していきます．まずはモデルの低層部分である，文字の画像を次元削減し，再び文字の画像を生成する部分（いわゆるオートエンコーダ）を学習します．下図のようにGeneratorの低層部分の出力から画像を生成し，元の文字の画像と一致するように訓練させることを順に行います． 該当するモデルの図． ここで難しいのが，どの程度までこのモデルを訓練させるかです．変換できる文字の種類を今回学習する文字[1]に限ってしまえば，母集団＝標本となるため，過適合がなく，訓練すればするほど精度が上昇するのですが，それ以外の文字もある程度変換できるようにしたい場合は早期に切り上げる必要があります． 今回は，頻出する構造がはっきりと再現できる程度に訓練をしました．特に再現に時間がかかった構造としては，かなの半濁点，諫などの内部の点，馬へんなどのれんがの部分があります． 訓練途中の結果．それぞれ左側は入力，右側が出力された画像となっている． 誰ですかこんな漢字を考えたのは． また，この訓練の損失関数は初めはL1損失を用いました．フォント画像を出力するので，ぼやけた画像よりも二値化されたような画像のほうが望ましいためこの選択をしたのですが，意外と学習が遅く，数千エポック回しても下図のような細かい構造が再現できませんでした．これをもってL2損失に切り替えたところ，100エポックほどで以下のような画像を出力しました．この時は出力にシグモイド関数を挟んでいたため，L2損失を使うと勾配消失が起きるのではないかと思っていましたが…難しいものですね． 左から，入力，L1損失で学習した際の出力, その後L2損失で学習した際の出力．口の横棒や，髟を見ると違いが分かりやすい． 訓練2 ようやくGANとしての訓練を始められますが，その前に．Generatorが生成した画像の分類を行うDiscriminatorを説明します． まず，Generatorが生成した画像か変換先のフォントの画像かを判別する通常のDiscriminatorを用意します．これには前述の画像のほかに，Genarotrに入力した画像と同じ変換先のフォントの組も同時に入れます．これにより，DiscriminatorはGeneratorが作った画像かどうかというよりは，入力された画像の文字が同じフォントに属するかという判定を行います． これに加えて，入力された画像が何の文字かを判定するCharaDiscriminatorも用意しました．これは文字の代わりにそれに対応する特徴量ベクトルを出力します．訓練はこの特徴量がGenerator内のCharaEncoderの出力と一致するように行います． 以上の分類器とともに以下の図のように2つの損失を算出し，最小化させていくことでGeneratorを訓練していきます．同時にDiscriminatorにも損失関数を用意し，訓練させています． Generatorの訓練の様子．Generatorだけでなく2つのDiscriminatorも用意して損失を算出する． Generatorが出力した画像(とそのほか必要な入力)をそれぞれ分類器に入れ，Generator, 分類器ごとにそれぞれの損失関数を最小化しさせました． (途中)結果 今のところの結果をあげておきます． まずはうまくいっている(ように見える)例から．以下で挙げる画像は，左から，変換したい字(入力)，変換先の教師画像，Generatorの出力結果，変換したいフォントで書いた字の画像2組(入力)となっております． validデータの変換の例． この例については，教師画像とはあまり一致していないように見えますが，例えば横棒が終端が太く，それ以外は細いといった特徴は表現できているように見えます． もちろんこんなにうまくいくものばかりではありません．下のようになんか背景が真っ白になっている時があったり， validデータの変換例2． ゴシック体と大きく異なるフォントは全然学習できてなかったりとなかなか課題は多そうです． trainデータの変換例2． ほかにも， 明らかに他の画像の特徴で表現されている →他の画像の学習結果が大きくでてしまった? 周りに変なごみが出る(うまくいった例の画像などにも出てる) ^ , .などの小さい字が異様に膨らむ などの問題があります． また，フォントの大きさの変化，回転などといった特徴は表現できないことも分かっております，これはおそらくフォントのエンコードをする部分で主にConvolutionレイヤを使っているモデルを使用していることが原因だと思いますが，特に支障をきたさなそうなのでそのまま訓練を続けようと思っております[2]， 感想 とにかくGenerator, Discriminatorの訓練バランス調整が難しく，崩れた途端意味のない画像しか生成しなくなるので，苦戦させられました．その調整ができても，訓練に時間がかかるという問題があり，それを改善しようとしてバランスが崩れる… というようなイタチゴッコが続いており，つらいです． ただ，今のところはうまくいってそうでその点は少し気が楽なので，もう少し続けてみようと思います． 備忘録 初めてのGANの訓練でつまずいたところ，気づいたところを書いておきます． Dのちょうどいい正解率がよくわからない 50%がちょうどいい正解率らしいけど，Dが全然学習してないときとの区別ができない とりあえず65~55%あたりにしてみる G, Dのバランス調整はdropout率を動かすのが早い Dの正解率等に応じて動的に調整できればなお楽 人の実装はしっかりコードを読んで意味を確認してから使うこと 自分の直感とは違う書き方がたまにされている これで損失関数の符号が逆になったまま訓練してました() メモリが足りなくなったらdel; torch.cuda.empty_cache(); gc.collect()をする バッチサイズを大きくして訓練できる でもこれをすると逆効果になることもある 地味に時間も食うので毎iterationやるときなどは必要がなければ使わないほうがいいかも 勾配を伝播させる必要のないテンソルはdetach()で計算グラフから切り離す しなくてもバグらないけどメモリをかなり無駄遣いする GANで必須のテクニックだと思うけど意外と解説が少ない気がする line_profilerやtorchinfo.summaryで時間，メモリの無駄遣いをしているところを探す 損失関数をAdamにこだわらない RMSPropやAdamWが意外といけるときもある 余談 最後に，訓練中の出力画像を表示してくれたTensorboard君の渾身の煽りを御覧ください． (こ)ここガバ 使用させていただいたフォント しろくまフォント FZイモケンピ 棘薔薇フォント Nuきなこもち ASCII文字，かな，JIS第一，第二水準の漢字 ↩︎ むしろそのような変化を吸収出来たほうが都合よい気がします(写真で撮影したものからフォントを生成したいときなど) ↩︎","link":"/2021/12/23/deepL/20211223/"},{"title":"Joplin (Katex)でマクロを使う","text":"最近，Joplinというマークダウンエディタを使っているのですが，\\newcommand{}でマクロを使おうとしたところ，$$で囲まれた中でしか適用されなかったので困りました．どうやらこのソフトはレンダラーにKatexを使っていて，Katexの仕様上こうなることは仕方ないみたいです． 開発者はレンダラーとしてMathjaxを使う気は全くないようなので，対策を探しました． 対策 \\gdefまたは\\global \\defというコマンドを使えば良いらしいです(初耳だった…)．詳しくはこれらについて解説するサイトに譲りますが，例えば， 123$$\\gdef \\data #1{\\mathcal{D_{#1}}}$$$\\data{s}$ のようにすればと表示してくれるようになります． Katexをレンダラーにしている他のエディタでも使えそうなので一応メモしておきます．","link":"/2022/05/23/memo/JoplinMacro/"},{"title":"MarkdownのCSSを絶対パスで参照する方法","text":"最近，Marp (Markdownでプレゼンのスライドが作れる拡張) などでMarkdownを記述する際，CSSをよく参照するようになりました．いくつか作ったCSSを定型デザインとして様々なファイルから参照したいので，絶対パスで参照したかったので，その方法をメモしておきます． 問題 解決手法 問題 VSCodeの設定で&quot;Markdown: Styles&quot; (Marpの場合はMarkdown Marp:Themesも)の設定を開くと使用するCSSのパスを登録できますが，これはURLかローカルの相対パスしか指定できません (セキュリティ上の問題があるみたいです)． なので，ナイーブな手法としてはワークスペースを作るごとに相対パスで設定するなどの手法があるわけですが…非常に面倒ですね． 解決手法 URLでは指定できるので，どこかしらのWeb上にCSSだけ上げてそれを参照すればよいです (CSSがWeb上に公開されてしまうという問題はありますが…)．一番手軽なのはGithub上に公開リポジトリを作成してそこに上げてしまうというものです． 上げたファイルをGithub上で開いて右上のRawボタンを押すと，そのファイルをブラウザ上で開けるので，そこのURLをCSSとして指定すればめでたく適用できます．","link":"/2022/06/15/memo/MarkdownCSSAbsolutePath/"},{"title":"Google Search Consoleにサイトマップが登録できないときの対処(4&#x2F;18 解決)","text":"Github Pagesでブログを作った際，Googleの検索結果にヒットさせるには，Google Search Consoleにサイトを登録する必要があります．その際，サイトマップを作成して登録するのですが，それが認識されなかったのでメモしておきます． Hexoでのサイトマップの作成，登録手順については以下のリンクなどをご覧ください． Hexoでsitemap.xmlを生成 現状 対処 別のライブラリに変えてみる 別の形式で作ってみる robots.txtに不備がないか とりあえずの結論 解決 (4/18追記) 現状 このように「サイトマップを読み込めませんでした」とだけ表示され，どういう原因なのかが全くわかりません． なお，サイトマップにはしっかりアクセスできます． こちら 対処 別のライブラリに変えてみる hexo-generator-sitemapでなく，上の記事でも紹介されている hexo-generator-seo-friendly-sitemapをインストールして，それで作成したsitemap.xmlを登録して見ても変化なし．この時作成されるpost-sitemap.xmlなどのサブセットも登録してみても変わらず． 別の形式で作ってみる Google検索セントラルのサイトマップの作成と送信によると，サイトマップの形式としてxmlファイルの他にtxtファイルも認められるとのこと． 形式は至ってシンプルで以下のようにウェブページのURLを羅列するだけ． https://hn410.github.io/ https://hn410.github.io/2022/01/09/memo/TexLiveShellError/ https://hn410.github.io/2022/01/09/univ/CPUExp1/ https://hn410.github.io/2022/01/08/univ/CPUExpChange/ https://hn410.github.io/2021/12/23/deepL/20211223/ https://hn410.github.io/2022/01/09/play/BrainF15/ https://hn410.github.io/2021/12/19/deepL/20211219/ とりあえずテストとしていくつかのウェブページを羅列したtxtファイルをアップロードし，それを登録…が，駄目っ!．変わらず…! robots.txtに不備がないか とにかく，そもそもクローラが私のウェブページに到達していないことがなんとなく推測されます． ということなので，robots.txtに不備がないことを確かめます．Search Consoleのヘルプにrobots.txt テスターで robots.txt をテストするというページがあり，そこからrobots.txtがGoogleのクローラをブロックする設定担っていないかを確かめられます． これでGoogleのクローラがブロックされているかを確かめてみますが…全部OKでした．まあ，そうですよね…. とりあえずの結論 こちらによると，どうやら日がたてば状況が改善されることもあるみたいなので，とりあえず待ってみます．それまでこの備忘録も検索結果に載らないままです(悲C)． 解決 (4/18追記) 海外のサイト等も含めて情報を漁ったところ，sitemapをgoogleに提出するもう一つの方法があるとのこと．それが，以下のURLの[サイトマップのURL]を自分のブログのサイトマップのURLにして，そこにアクセスするというもの． https://www.google.com/ping?sitemap=[サイトマップのURL] これを行って約半月後に ようやくやりました．まだページ全体が検索結果に載っている訳ではありませんが，後々載ることでしょう．これでようやくこの記事も日の目を見ます．","link":"/2022/01/10/memo/GoogleSearchConsoleError/"},{"title":"Markdownで表の幅を調節する方法","text":"Markdownには表の幅を調節する機能がありません．レンダーにもよると思いますが，たとえばHexoのデフォルトのレンダラーでは表の幅が全体に広がってしまい場合によっては不格好です． 無理やり空白を入れて幅を広める方法はあるみたいですが，幅を縮める方法がなかなか見つからなかったのでメモしておきます． 普通の表 対策 普通の表 例えばこのように記述すると， 12345| col1 | col2 || :--- | :---: || hoge | 1 || fuga | 0 || poyo | 2 | こうなります． col1 col2 hoge 1 fuga 0 poyo 2 各行の内容が少ないのにもかかわらず幅をとってすごく見づらいですね． markdownはhtmlが使えるので&lt;table&gt;タグでwidthを指定しようとするとそれ以降の内容もhtmlで書かなくてはならないので非常に不便です． 対策 今回は&lt;style&gt;タグを利用してクラスごとに&lt;table&gt;のwidthを指定します．&lt;style&gt;タグは本来，&lt;head&gt;内に書くものですが，少なくともmarkdownの場合は本文中でも動くようです． 1234567891011121314151617&lt;style&gt;.uooo table { width: 40%; margin: auto; }&lt;/style&gt;&lt;div class=\"uooo\"&gt;| col1 | col2 || :--- | :---: || hoge | 1 || fuga | 0 || poyo | 2 | &lt;/div&gt; .uooo table { width: 40%; margin: auto; } col1 col2 hoge 1 fuga 0 poyo 2 これでうまく調整できました．なお，divのwidth属性に直接設定しても変更ができなかったので，これが無難かと思われます．","link":"/2022/05/05/memo/MarkdownTableWidth/"},{"title":"Tex Live Shellが落ちる, tlmgr install ができないときの対処","text":"部誌を作る際にはまったのでメモ． Texを最小限の構成でインストールした場合，コンパイル時に! LaTeX Error: File [ファイル名] not found.のエラーが出たときはその都度必要なライブラリをTex Live Shellやtlmgrからインストールする必要があります． Tex Live Shellを起動し，何らかの操作をするとBack end gone. Last command: ...というエラーを出して落ちました．これの対処法を記します． 対処 セキュリティソフトのウェブ保護の設定を一時的に切れば正常に動作します． …まあ，言われてみれば基本的な対処ですが，最近セキュリティソフトの質も上がったせいか，すぐにはこの操作をしようと思えないんですよね． なお，tlmgr install [ファイル名]の実行時にTLPDB::from_file could not initialize from: [インストール先のURL] と出る時もこれで解決することがあります．これで解決しなかったらそのURLがまだ生きているかを確かめましょう．","link":"/2022/01/09/memo/TexLiveShellError/"},{"title":"BrainF*ckで15パズル","text":"折角ブログをつくったので，部誌で書いた記事を少し改変してここで再掲したいと思います． プログラミングを学び始めたときに初心者用の言語としてBrainF*ckが紹介されていたので，それで作った15パズルを紹介します．この言語についてはネットに沢山解説記事が上がっているのでそちらを参照ください． プログラム 概要 メモリの割り振り 初期設定 入力キーの判定、移動処理 描画 まとめ プログラム 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384 ※po=xはポインタの位置がｘ番メモリにあるの意味。最初のメモリは１番メモリとする。 指定されたメモリにパズルの番号＋６６を入力。改行の箇所には１０、空白は０、その他は１+&gt;+&gt;+&gt;+&gt;++++[&gt;++++&lt;-]+&gt; po=6[&gt;++++&gt;++++&gt;++++&gt;++++&gt;+&gt;&gt;++++&gt;++++&gt;++++&gt;++++&gt;+&gt;&gt;++++&gt;++++&gt;++++&gt;++++&gt;+&gt;&gt;++++&gt;++++&gt;++++&gt;&gt;+ po=29&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;-]+ po=6&gt;+++&gt;++++&gt;+++++&gt;++++++ &gt;------&gt;+&gt;+++++++&gt;++++++++&gt;+++++++++&gt;++++++++++ &gt;------&gt;+&gt;+++++++++++&gt;++++++++++++&gt;+++++++++++++&gt;++++++++++++++&gt;------&gt;+&gt;+++++++++++++++&gt;++++++++++++++++&gt;+++++++++++++++++ &gt;&gt;------&gt;+&gt;+&gt;+&gt;+&gt;+&gt; ここまで初期設定 po=35 以下ループ ※一旦１を代入しておいてループの部分が飛ばされてしまうのを防ぐ+[- ここから描画処理 マスの先頭へ&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; po=7 全体にー２して出力させることで、空白のメモリをー２＝１２６にし、チルダを出力させる。 --.++&gt;--.++&gt;--.++&gt;--.++&gt;.&gt;&gt; --.++&gt;--.++&gt;--.++&gt;--.++&gt;.&gt;&gt;--.++&gt;--.++&gt;--.++&gt;--.++&gt;.&gt;&gt;--.++&gt;--.++&gt;--.++&gt;--.++&gt;.&gt;&gt; po=31&gt;&gt;&gt;&gt; po=35 以上。入力へ, 読み込んだ値を３６、３８、４０、４２にコピー [-&gt;+&gt;&gt;+&gt;&gt;+&gt;&gt;+&lt;&lt;&lt;&lt;&lt;&lt;&lt;] po=35 入力がAかどうかの判定 &gt;&gt;++++++++++++[-&lt;--------&gt;]&lt;- ３６の値から９７を引く、po=36 &gt;+&lt;[&gt;-&lt;[-]]&gt;[ Aならここを実行、あとは飛ばす po=37 ３８、４０、４２に十分大きな値を入れて負になるのを防ぐ。 &gt;&gt;+++++[&lt;+++++&gt;-] &gt;&gt;+++++[&lt;+++++&gt;-] &gt;&gt;+++++[&lt;+++++&gt;-] po=43 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; po=33 [&lt;] パズルの空白の位置まで移動 &lt;-[ 空白の左隣が１じゃないならここを実行 [&gt;+&lt;-]&gt;+&lt;] 左隣の値を空白に移動 +&gt;[&lt;-]&gt;&gt;&gt;[&gt;] もし空白だったところの左隣が１だったら、現在０になっているので、そのときのみ１を足して元に戻す po=35 &gt;&gt;-] ３７番を０にする 以上、Aの判定 Dの判定 &gt;&gt;++++++++++[-&lt;----------&gt;]&lt; po=38 &gt;+&lt;[&gt;-&lt;[-]]&gt;[ po=39 &gt;&gt;+++++[&lt;+++++&gt;-] po=41 &gt;&gt;+++++[&lt;+++++&gt;-] po=43 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&lt;] &gt;----------[ [&lt;+&gt;-]&lt;++++++++++&gt;] ++++++++++&lt;[&gt;----------]&gt;&gt;[&gt;] &gt;&gt;&gt;&gt;-] if po 38 = d now po=39 Sの判定 &gt;&gt;+++++++++++[-&lt;----------&gt;]&lt;----- po=40 minus115 &gt;+&lt;[&gt;-&lt;[-]]&gt;[ po=41 &gt;+++++&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&lt;] &gt;&gt;&gt;&gt;&gt;&gt;-[ [&lt;&lt;&lt;&lt;&lt;&lt;+&gt;&gt;&gt;&gt;&gt;&gt;-]&lt;&lt;&lt;&lt;&lt;&lt;+&gt;&gt;&gt;&gt;&gt;&gt;] +&lt;&lt;&lt;&lt;&lt;&lt;[&gt;&gt;&gt;&gt;&gt;&gt;-]&gt;[&gt;] &gt;&gt;&gt;&gt;&gt;&gt;-] if po 40 = s now po=41 Wの判定 &gt;&gt;+++++++++++[-&lt;----------&gt;]&lt;--------- po=42 minus119 &gt;+&lt;[&gt;-&lt;[-]]&gt;[ po=43 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&lt;] &lt;&lt;&lt;&lt;&lt;&lt;-[ [&gt;&gt;&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;&lt;-]&gt;&gt;&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;&lt;] +&gt;&gt;&gt;&gt;&gt;&gt;[&lt;&lt;&lt;&lt;&lt;&lt;-]&gt;[&gt;] &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;-] if po 42 = w now po=43&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; po=35 出入力へループ+] 概要 A～Nはそれぞれ１～１５に対応し、?が空白となっております。操作はBrainFckの入力パネルにw(半角)を入力することで空白に対応する部分が上に、a,s,dも同様にそれぞれ左、下、右に動きます。 BrainFck製である以上、以下の欠陥があります。 シャッフル機能がないです。なんか適当に文字入力してもらうのも考えましたが、面d(ry インタプリタによっては、入力してもまた入力ウィンドウがでる無限ループに入ります。 メモリの割り振り 使用したメモリの数は４３です。下に主な用途を書きますが、この言語の特性上このほかにメモリをいろいろ使いまわします．例えば３５、３６はパズルの描画のために「６３」を一時的に作るために使われます。 メモリの位置 主な用途 備考 １～３４ パズルのマスに対応 なぜ３４マスもあるかは後述 ３５ キーの入力値を一時格納 すぐに３６,３８,４０,４２にコピー ３６,３７ Aが入力された時の判定 以下、４２,４３までそれぞれD,S,Wに対応 初期設定 まず、マスの状況を保存する部分をはじめに１５パズルの揃った状況に設定します。ここで、本来の１６マスよりも大幅に多い３４個のメモリを使う理由ですが、下のように４×４のマスを６×６に拡張したためです（いわゆる番兵の設置）。 このようにメモリを拡張することで、実際に用いる真ん中の１６個のメモリのある場所からの上下左右が常に±１、６になります。このとき、パズルに対応する１６個のメモリのうち、数字に対応する部分はその値＋１を、空白の部分は０を格納します。周囲のメモリは１を入力しておきます。空白に対応する部分を０にすることで、‘’]''の命令で０か正かしか判定できないこの言語で後で参照しやすくします。 入力キーの判定、移動処理 この後、入力待ちの状態にし、３５番メモリにそれを8ビットの整数で代入させ、それを４箇所にコピーします（コピー元は消えちゃいます）。入力が予想される値はa(９７),d(１００),s(１１５),w(１１９) {括弧内は文字コードの１０進数値}で、まず文字コードの値が若い順に処理します。コピーした値のうち１つから９７を引き、０になるかを判定します。（この判定の書き方はこちらをパクらせていただきました。）もし０ならさっきコピーした残りの値に十分大きな値を足しておいて（別の値の判定で９７より大きい値を引いて負にさせないため）、パズルの移動にかかります。といっても１～３４のメモリの中で０になっている値とその左隣の値を交換するだけなので単純です。ただし、空白の左隣がパズルの４×４マスの外（つまり値が１）なら、その移動は実行しません。 この処理をd,s,wでも行います。 描画 移動処理が終われば描画するだけですが、これはマスの状態が記録されてるメモリに６３を足して出力する(Aの文字コードの値は６５)だけなので大したことないです。３５、３６番メモリ（このとき、値は常に０です）に６３をあらかじめ作っておき、一気に該当のメモリに足したあと順に出力します。このとき、パズルの４*４のマスの右の外にある列に対応するメモリの値は１０にして改行を出力させます。 あとはメモリの値を元に戻してループさせるだけです。 まとめ 今思うとよくこんな面倒なものを作ったなあと思いました。この時期にNP性の証明とか書かせてたらチューリングマシンの動作をきちんと書いてたかもしれません。","link":"/2022/01/09/play/BrainF15/"},{"title":"CPU実験の振り返り(シミュレータ係，前編)","text":"私の所属する学科の名物実験であるCPU実験も大詰めに近づいてきたので，このあたりで途中経過を振り返ってみたいと思います． CPU実験についての説明は先輩方が丁寧に説明したくださっている記事があるのでそちらをご覧ください．「CPU実験」と検索すると沢山ヒットします． また，私の代でこの授業に大幅な変更がありました．詳しくはこちらをご覧ください． 9月後半 軽い予習 10月前半 顔合わせ，初期ISA決定，Fibシミュレータ作成など 10月後半 GUIの作成, FPU, メモリの組み込み 11月 機能拡張，高速化，1stシミュレータの完成? 9月後半 軽い予習 このあたりでどの係にするかの希望を出します．先輩のブログや説明資料から考えて，私はシミュレータ係を希望し，そのまま通りました．コンパイラ係の希望が少し多かったので，一部の人がコア，FPU係に移動していました． 係も決まり，特にすることもなかったので軽く予習をしておくことにしました．CPU実験のシミュレータは他の係がデバッグに用いるため，なるべく高速に動作することが求められます．そのため，CやC++のような高速な言語で開発するほうが好ましいです．また，班員がコードを確認したり，改造を加えたりすることもあるので，班員も扱える言語のほうがよいです．Cは必修だったので全員使えますが，あまりにもライブラリが乏しいため，C++を使うことにしました．私はJavaをよく使っていたのでこれの履修には特に苦労しませんでした． 10月前半 顔合わせ，初期ISA決定，Fibシミュレータ作成など 10月になって班の割り振りが決定され，ここから進捗発表会が始まります． 最初の1週間でISAとしてRISC-Vのサブセットを使うことを決定しました．大体の班が同様な決定をしていましたが，配布されるコンパイラがデフォルトでPowerPCのアセンブリを出力できることからそれをISAとして使った班もありました． ここからまずはフィボナッチ数を計算できるコアの作成を目指します． シミュレータ係としてはいかに早くシミュレータを作成して班員が使えるようにするかが重要だと思ったので，ISAの決定の数日後にはアセンブリの書式の決定とそのインタプリタの作成を終えました．この後必要そうな機能を追加していきます．例えば， ブレークポイント機能 命令の巻き戻し機能 実行命令数などの統計情報表示 などが挙げられます．統計情報はデバッグにはあまり使いませんが，コンパイラやISAの改良を行う際に使われました． アセンブラについては，コア係が作ってくれたものを互いに機能拡張するという形で開発しました． 10月後半 GUIの作成, FPU, メモリの組み込み このあと，GUIの作成をした班があったので，対抗して(ほぼ自己満のために)GUIの作成にもとりかかりました．JavaでGUIを作ったことは何度かあったので，メインの処理は今まで作ったCLIのソフトにさせ，それとプロセス間通信をさせる形でJavaのGUIを作成しました．一応コア係には好評だったのでよかったですが，他の機能拡張を優先すべきだったかもしれません． また，このころFPUのVerilogでの実装が少しずつ上がっていたので，それをC++に落とし込む作業をしました．本来のハードウェア開発ではシミュレータが作成→それとまったく同じ挙動をするようにハードウェアを開発の順番なのですが，仕事の分担の関係上，FPUに関しては逆転してしまうのは仕方ない気がします．久しぶりのVerilogのコードに戸惑い，検証のコードにバグを仕込むというやらかしを行い，FPU係に迷惑をかけてしまいました(すみません)． でも，これだけは言わせてください．C++のシフトの仕様は罠です[1]． あとメモリの組み込みもこの頃行いました． 班の進捗としてはこの頃フィボナッチ数を計算できるコアはできていた気がします． 11月 機能拡張，高速化，1stシミュレータの完成? 以降，FPUが作ってくれたコードをC++に落とし込みながら機能拡張を続けました．この頃行ったものの例としては， エントリポイントへの対応 ディスアセンブラの作成 ワードデータを以下の表記で相互変換できるツールの作成 符号有無と2・10・16進法の変換 メモリの実装と同じエンディアンでエンコードしたときの4バイト 高速化 gprofでどこが時間かかっているかを調べられる アセンブラを作ると同時にディスアセンブラを作っておけばアセンブラのデバッグをかなり効率化できたので，これについてはもっと早く作っておくべきだったなと思っています． 以上とMMIOによる通信とキャッシュのシミュレータを追加して，1stコアのシミュレータを終えました．例年であればここで単位を確定できるのですが，今年からは速度予測が必須になるので，コアが完成させて速度予測に必要となるパラメータを収集できるまで単位はお預けです． 班の進捗としては，月の終わりにコンパイラ係がレイトレのプログラムをコンパイルでき，シミュレータ上で画像生成をすることができました(この際にシミュのバグをコンパイラ係に指摘してもらいました…申し訳ない)． 執筆現在1月なので，12月の振り返りも書けるのですが，バランスを考えて全部終わったときに以降は書きたいと思います． 論理シフト，算術シフトの区別がない．ビット幅以上のシフトが未定義． ↩︎","link":"/2022/01/09/univ/CPUExp1/"},{"title":"CPU実験の振り返り(シミュレータ係，後編)","text":"最終発表からかなり遅れてしまいましたが，これ以上遅くなって記憶が風化しないうちにメモします． 前回の続きとして12月から書いていきます．前回の記事を読んでない方はこちらからどうぞ． 12月 2ndシミュレータ完成 1月 1stシミュ時間予測完了，1stコア完動，班全員単位確定 2月 2ndコンパイラ完成，2ndコア完動，2ndシミュ時間予測完了． 感想 12月 2ndシミュレータ完成 コンパイラがとりあえず動き，コアも完成に近づいたところでISAの改善点が浮かび上がってきました．具体的には， シフトの即値命令，lui(addi命令1回で即値を埋められない桁に即値を埋める命令)がほしい アドレス等，桁の大きい即値を作ることが頻繁にあったため 浮動小数点レジスタと整数レジスタの区別はないほうが良い 浮動小数点の即値を入れるのが大変だったため ブランチの即値をより長くとれるように 自班のISAでは簡単のため，4バイトアラインされた位置にしかメモリアクセスしないので2桁節約可能 などがあります． この中でも特に効果の大きいlui命令は1stISAにも組み込み，残りは2ndISAとしてまとめて改善を行うことにしました．自班の1stISAではlui命令がないと32ビットの即値を作るのに最大で8命令(シフト命令とaddi命令の繰り返し)かかったのでluiは必須といっても過言ではありません． 以上，2ndの仕様が決まったので，シミュレータは先周りして2ndシミュレータを作成しました． この時，1st, 2nd共通の機能拡張も行いましたが，今考えてみれば蛇足だったと思う機能もありました．レイトレのプログラムの実行に予想以上に時間がかかったので，統計情報などをとらないことで実行だけを高速に行える機能をこの頃実装しました．確かに早くはなったものの，シミュ係の私として後々頻繁にシミュレータを使うことになるのは速度予測をテストするためであり，これには細かな統計情報が必要だったので，私はこの機能をあまり使いませんでした．コア係やコンパイラ係は使ってくれるかもしれませんが，個人的にはあまり使えなかったなと思いましたので，高速化するとしたら別の手法がおすすめです． また，この月の後半にはコア係がデバッグ地獄に巻き込まれていました．私はそれなりにフリーであったものの，直接助ける術はなかったのでまごついていました．とりあえずテストプログラムのアセンブリをできるだけ書いてほしいといわれたので，バグを見つけやすそうなプログラムをいろいろ書きました．コンパイラを経由すると思った通りのコードにならないので，直接アセンブリをスムーズに書ける能力もあるとよさそうです． 1月 1stシミュ時間予測完了，1stコア完動，班全員単位確定 短い冬休みの余韻に浸ってしばらくたつと，コア係からとりあえず画像は出力できたという報告が． ……背景が赤いし，視点も違うし，なんか右上にヒストグラムみたいなのが出てるし…．とりあえず床の模様が出ていないので，「床がおかしければfloor関数を見直せ」という実用的な激うまギャグにに従うと… とりあえず進歩したものの，見慣れた画像とは程遠い…．全体が大きく異なるので，局所的な問題ではないだろうと推測を進め，「浮動小数点テーブルがおかしいのではないか」という意見が出ました．これを見直した結果…． 感動しました！ 実機の結果とシミュレータの結果もdifをとって差がないことを確認し，めでたく単位確定です． …と言いたいところですが，シミュ係にはまだ時間予測が残っています． あらかじめ作っておいたシミュレータの時間予測と実機の結果を比べると，速度競争で使うSLDファイルではギリギリ5%以内の精度で予測できたものの，実行時間が短いものほど誤差が大きくなっている模様．様々なファイルで実行時間の絶対誤差を調べたところ，定数分ずれているどころか，反比例するような傾向が見られました．実行時間が短くなるほど遅くなるような機構を様々考え，UART通信のキューが詰まっているのではないかと気づきます．今まではキューは詰まっていないという仮定をおいていたので，新たに近似的なキューを実装し，シミュレーションを行い，それも考慮に入れた時間予測を行った結果，ほとんどのSLDファイルで5%以内の時間予測ができました． これにより単位が確定しました(速度予測で必要なSLDファイルだけ精度が高ければよかったのですが，この頃はそのことを知らなかったので，とりあえず精度を上げようと必死になっていました)． 2月 2ndコンパイラ完成，2ndコア完動，2ndシミュ時間予測完了． 試験が終わり，一段落したところで，2ndコンパイラ完了の知らせが届き，2ndコアの開発，デバッグが本格的になってきました．この時点で発表まで残り数日しかなかったため，時間予測のためにコアを待っている余裕はなく,私も急いでそれに取り組みます． 2ndコアも1st同様デバッグに悩まされ，前日は班員で徹夜をしてそれぞれの作業に取り組みました．今回はクラス全体で進捗が例年より遅れていたため，多くの班が発表会には2ndコアを間に合わせようと前日(当日)徹夜をしていました．私は朝6時まで時間予測の改善と発表資料作成に取り組んでいましたが，自班を含め徹夜をしていた班から完動報告が来なかったため，半分諦めて3時間程仮眠をとりました．起きてみると，私が寝た1時間後に2ndコアが完動したという報告がコア係から来ていました．徹夜をしていた中で2ndコアを完成させたのは彼だけだったので，彼の勝負強さ，根気強さには感服します．急いで時間予測に掛け，何とか発表会前に配布されていたSLDファイルすべてでの時間予測を行い，7~8割近くのファイルに対して5%以内の精度で時間予測ができたことを確認しました． しかしながら，同時に最適化をしていたコンパイラ係から，最新の最適化を施したコードが動かないという報告が．おそらくシミュレータ，アセンブラのバグではないかと思われていましたが，複数ファイルで精度の高い予測をしなければならないと勘違いしていたため，時間予測の確認に追われてそちらの対応に間に合わず，最後の最適化は最終発表には組み込めませんでした．徹夜までしてもらったのに申し訳ないです…． しかしながら，班員のファインプレーが重なり，8班中3位，実行時間42.3sを達成しました．今回はボードの性能低下，必須要件の増加などがあったため，もう少し遅い結果になってもおかしくないと思っていたので驚きました．やはり班員の皆さんは偉大です…． 感想 シミュレータ係としてCPU実験に参加してみた感想として，最初と最後に負担が大きいというのがまず挙がります．シミュレータはほかの係のデバッグツールになるため，できるだけ早く(そして速く)動くものを作らなければなりませんし，コアが動いてから時間予測の確認もあります．コアの完成がかなりギリギリになると予想されるため，シミュレータ係はコアが動く前にほぼ時間予測を完成させなければなりませんし，コアの完成から発表会までのわずかな時間で確認と微調整を終わらせなければなりません．逆にそれ以外は自分や班員の役に立ちそうなものを作ったり，班員のリクエストに答える以外は割とフリーになります．ただ，班員のリクエストにはなるべく早く答えられた方がいいので，全体的にフリーな時間が多いほうが向いているかもしれません（どの係にも言えることですが）． また，ここまで大きなグループ開発も行ったことがなかったため，新鮮でしたし，最後の徹夜も含めてなんだかんだ楽しかったです．でもどうせなら地下でいろいろ取り組みたかったなあという思いもあります．今年は使えるようになるんでしょうかねえ…．","link":"/2022/03/08/univ/CPUExp2/"},{"title":"CPU実験の変更点(暫定)","text":"あけましておめでとうございます． この記事にアクセスしてくださった方はご存じかもしれませんが，東京大学理学部情報科学科ではCPU実験という名物授業があります．どんな授業かというと，班員で役割分担をし，mincamlという言語で書かれたプログラムを動かすデバイスをFPGA[1]で1から作るという授業です．詳しい概要については先輩方が書いたブログなどにも書かれているのでそちらをご覧ください． しかしながら，担当教員の変更と去年に引き続いて例のウイルスの影響を受け，今年から大幅に内容が変更されました． これが永続的なものかはわかりませんが，記録として残しておきたいと思います．もし，後輩の方が私より前の世代の方のブログを見る際に参考にしていただければと思います． 全般 授業が対面→オンラインと対面のハイブリッド型へ (地下が利用不可能に) ハードウェア 配布されるFPGAボードの性能が低下 DDR2メモリの使用が性能的にほぼ必須に 単位要件 コンパイラ実験の課題の割り振りの変更 FPU係がFPU・メモリ係に変更 キャッシュの開発が必須に シミュレータ係に実行時間予測のタスクが追加 発展課題として512×512の画像サイズのレイトレが追加 全般 授業が対面→オンラインと対面のハイブリッド型へ コンパイラ実験は完全オンラインですが，プロセッサ実験は生徒が対面，オンラインを自由に選べます．しかし，対面授業は他の班の同級生と情報交換ができる貴重な場だった[2]ので多くの人が対面で受けていました． (地下が利用不可能に) 去年に引き続き，地下が利用不可能となった状態で開発を行いました． おそらく2022年は使えるはず…? ハードウェア 配布されるFPGAボードの性能が低下 これは決して予算が削られたわけではなく(たぶん)，今までは班に一つ配布されていたものが一人に一つに増やされたためです[3]． これにより以下の変更が発生します． DDR2メモリの使用が性能的にほぼ必須に 以上より，FPGAのBRAMの容量が減ったため，特に工夫をしなかった場合，容量不足となります．そのため，BRAMをキャッシュとして用い，DDR2メモリをメモリとして扱うことを強いられます．後述しますが，キャッシュの開発も単位要件として追加されたので無理やりBRAMしか使わないようにすることは認められません． 単位要件 コンパイラ実験の課題の割り振りの変更 一部の個人課題がグループ課題になる，必須提出数の増加などがありました．全体的には負担が増した気がします． FPU係がFPU・メモリ係に変更 メモリの変化により，FPU係にキャッシュシステムを含むメモリ開発の役割が増えました． キャッシュの開発が必須に 前述したようにDDR2メモリの使用が必須になったため，これだけを使うと速度が著しく低下します．そのため，BRAMをキャッシュとして用いることが必須になりました． シミュレータ係に実行時間予測のタスクが追加 今までは動作のシミュレーションだけを行うソフトを作れば単位を確定できましたが，それに加えてハードウェアでプログラムを実行した際にかかる時間をある程度の精度で予測することも必須要件に加えられました．これにより，今までは仕事がなくなっていた学期末に仕事が入ります． 発展課題として512×512の画像サイズのレイトレが追加 必須要件は128×128の画像のレンダリングの速度競争ですが，発展としてその4(16)倍の大きさの画像のレンダリングの速度競争が行われます． 書き洩らしがあればご一報願います． プログラムで自由に回路を変更できるデバイス ↩︎ DiscordやSlackもありますがやっぱり対面のほうが話しやすいです ↩︎ 完全オンラインになっても全員が手元で動作させられるようにするため ↩︎","link":"/2022/01/08/univ/CPUExpChange/"},{"title":"Latexの数式のOCRを無料で行えるツール","text":"論文のメモをMarkdownでとるときなど，数式の画像をlatexの書式に変換したいことはかなり頻繁にあると思います．最近はMathpixという便利なツールも出てきましたが，こちらは無料版では変換できる枚数に制限があり，学生にはちょっと手を出しづらいという人もいるでしょう． 今回はなかなかの精度でそれと同様なことができるOSSを見つけたのでそれを紹介したいと思います． 概要 CLI GUI 使用例 注意点 感想 概要 今回紹介するのは，LaTeX-OCRという機械学習ベースのソフトウェアです．Pythonのモジュールという形で公開しており，以下のようにpipを使ってインストールができます． pip install pix2tex[gui] CLIとGUIを用意しておりそれぞれ以下のように使えます． CLI 画像ファイルやクリップボードの画像をLatex形式に変換できます． pix2texを実行し，プロンプトを表示させます． 画像ファイルを変換したい場合はそのパスを入力，クリップボードの画像を変換したい場合は何も入力せずに確定します． Latexの書式で出力が表示されます． GUI スニッピングツールを使ってGUIで画面上の数式を変換できます． latexocrを実行し，ウィンドウを表示させます． Snipボタンを押して，スニッピングツールを起動させます．ここで，変換させたい画像を矩形範囲内に収めて指定します． しばらくすると変換されたLatexのコードとそのレンダリング結果が表示されます． 使用例 例えば，SN-GANの数式3 (下図)をこのツールで変換してみます． 手打ちでやろうと思うと億劫になりそうですが，結果は以下のようになっております．xのベクトル表記がうまくいっていないのを除けばほぼ完璧な変換をしてくれます． なお，満足な変換ができない場合，下のTemperatureを調整してからRetryを押すと，うまく変換できる場合もあります． 注意点 alignなどで数行にわたる数式などの複雑な数式，手書きの数式などはまだ対応していないようです．しかし，記事執筆現在も頻繁に更新がなされているソフトウェアなので，今後のアップデートでその辺りが修正されることは期待できます． 感想 OSSでここまで高精度でできるのはかなり素晴らしいことだと思います．Mathpixのほうは数回しか使ったことがないのであまり比較はできていないのですが，簡単で長い数式ならこれでも十分ではないかと思っています．","link":"/2022/06/16/tools/LatexOCR/"},{"title":"アニメ用動画補完最新モデル AnimeInterpの紹介","text":"画像処理のトップカンファレンス，CVPR2021に採択された論文\"Deep Animation Video Interpolation in the Wild\"を要約しました．この論文で提案されたモデルのAnimeInterpは，動画補完モデルでSOTAを達成した\"DAIN\"等に比べてアニメ映像の補完でより良い性能を達成し，SOTAとなりました． また，アニメ映像の補完タスクについて定義した論文は以前になかったことから，これについて定義し，さらに訓練，評価用のデータセットである\"ATD-12K\"を作成，公開されています．いずれもGithubで公開されております． .paper_info table { width: 80%; margin: auto; } 各モデルの出力結果の比較．AnimeInterpは細い筆まで的確に描写できている． 論文名 Deep Animation Video Interpolation in the Wild 著者 Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu リンク Arxiv, Github その他 CVPR2021採択 Abstract 1. Introduction 2. Related Work Video Interpolation Vision for Animation 3. ATD-12K Dataset 3.1 Data Construction Statistics 3.2 Annotation 4. Our Approach 4.1 Segment-Guided Matching Color Piece Segmentation Feature Collection Color Piece Matching Flow generation 4.2 Recurrent Flow Refinement Network 4.3 Frame Warping and Synthesis 4.3 Learning 5. Experiments 5.1 Comparative Evaluation Quantitative Evaluation (定量的評価) Qualitative Evaluation (定性的評価) 5.2 Ablation Study Quantitative Evaluation Qualitative Evaluation 5.3 Further Analysis Influence of Difficulty Levels and Motion RoIs User Study 感想 注釈 Trapped-ball algorithm Superpixel Superpixel pooling Variational optimization Convolutional GRU Abstract アニメ補完で難しい例．(a)はテクスチャが存在しないため，特徴点をとりづらい．(b)は剣の動きが大きく，複雑なため予測が難しい． アニメ補完は需要があるけど既存の手法ではなかなかいい結果が出ない．アニメ映像は自然映像に比べて以下２つの点で異なる． 問題1: 線と滑らかな色の領域で構成されていて，質感が存在しないため，（特に滑らかな領域については特徴点がないから）動きを予測しにくい 問題2: アニメの動きは強調されているため，非線形で動きが大きい この問題に対し，以下3つのことを行い，解決した． 初めて正式にアニメ補完問題を定義したこと． アニメ補完問題の訓練と評価を容易にするため，ATD-12Kという３つ組のアニメ画像にアノテーションがついた，巨大なデータセットも作成した． AnimeInterpという，アニメ補完問題でSOTAを達成したモデルを開発した． 1. Introduction アニメ補完問題には以上２つの問題がある．これに対し，以下２つのモジュールをもつAnimeInterpを提案する． Segment-Guided-Matching (SGM)で色ごとに領域をマッチングすることで質感のない問題 (問題1) を解決 Transformerのようなアーキテクチャで再帰的に動きを予測するRecurrent Flow Refinement (RFR)で，非線形で大きな動きを予測する (問題2) SGMは輪郭で区切られた同じ色の領域をまとめて扱って，オプティカルフローを計算する．これにより，SGMは極値問題を防ぎ，質感のない問題を解決する． この領域ごとのフローをRFRに入力して最終的な画像出力を得る． また，ATD-12Kという巨大なデータセットも作成した．これは合計25時間におよぶ，30の異なるスタイルのアニメ映画から得られた3つ組の画像データを作成した．テスト集合は動きや隠れ(occlusion)の大きさに応じて３つの難易度に分け，さらなる分析のために動きのカテゴリについてのアノテーションも追加した． 2. Related Work Video Interpolation Phase-based, Kernel-basedなどのモデルがあったが，小さい変化に対してしかうまくいかなかった．大きな変化に対しては主にオプティカルフローで取り組んでいる．しかしながらこれらはアニメには前述の問題でうまくいかない． Vision for Animation アニメに関する深層学習は様々な研究があるが，動画補完問題に取り組んだ研究は今まで存在しなかった． 3. ATD-12K Dataset アニメ動画補完問題の学習と評価のため，ATD-12Kというデータセットを作成した． 訓練用に10,000組の3つ組の画像 (1フレーム目，2フレーム目, その間の画像) テスト用に2,000組（訓練用とは異なるソースから取得） テスト用には豊富なアノテーションを付加し，様々なカテゴリで評価を行えるようにした． 難易度，動きの種類，Regons of Interest (RoI) 3.1 Data Construction 様々なソースから高画質な映像を入手．その中から3つ組のフレームを入手するが，ただ隣接する3組を選ぶだけでなく，変位を拡大するために1~2フレーム間をあけてとることもした．組の間で似た画像にならないように，構造的類似性 (SSIM)が0.95より大きいフレームが含まれる組は排除した．また，シーンの変化なども取り除くため，SSIMが0.75より小さいフレームが含まれるものも排除した． この後人の検査が入り，2人以上が適切と判断したものを残した．排除したものは例えば矛盾したキャプションがつけられていたり，単純で似たようなシーンだったり，不自然な動きだったりする． Statistics 自然映像とアニメ映像の隔たりを調べるため，自然映像の補完のデータセットして使われるAdobe240との動きの統計を比較した．ATD-12Kのほうがオプティカルフローの平均，分散ともに大きい値の割合が多いことが判明した． 3.2 Annotation 難易度は動き，隠れの大きさに応じてつけた 背景よりも，動いている部分のほうが印象に残るため，その部分をRoIとし，バウンディングボックスで2枚目のフレームにつけた． フレーム組の主な動きを区別するため，以下二つのアノテーションをした． 一般的な動きかた (移動，回転，拡縮，変形) キャラの動き (話す，歩くなど) 4. Our Approach AnimeInterpの構成 このモデルの主な流れは， フレーム画像をSGMに入力し，双方向の大まかなフローを得る． RNRの初期入力としてを入力し，精度の高い, が得られるまで次第に変形させる , をもとにを変形させて出力を得る となっている 4.1 Segment-Guided Matching アニメでは，各領域ははっきりした線で区切られ，その中は一色で塗られている．また，その色は動きが大きくても次のフレームでも変わらない．この手掛かりをもとに大まかなフローを作ることで領域ごとの滑らかな動きを実現する． Color Piece Segmentation まず画像にラプラシアンフィルタをかけて輪郭抽出をし，そのあとTrapped-ball アルゴリズムで色の領域(Superpixel)を生成する．これにより，画像と同じサイズの自然数の行列が得られる．各領域が固有の整数に対応し，例えばはの色の領域に対応するピクセルを表す．このSがSegmentaion mapであり，画像を各Superpixelに分けている． Feature Collection 画像を事前学習されたVGG-19に入力し，その途中出力relu1_2などを特徴量として得る．この特徴量をsuperpixel poolingを使ってで統合する．この結果，superpixel数 (の色数？), 特徴量数をとすると，サイズの行列がそれぞれ得られる．これはsuperpixelごとの特徴量ベクトルをまとめた行列である． Color Piece Matching ２フレームのsuperpixelを対応付けるマッピング, を学習する．例えばの色に対してを考えると，での対応する最も尤もらしい色を返すような関数を考える． まず，間の色の類似性を示す指標を導入する． は正規化した特徴量である． また，外れ値を除くため，二つの制限罰則項を加える． Distance penalty … 二つのsuperpixelの重心の距離を画像の対角線長で割ったもの この比が0.15以上だとよく働く Size penalty … 二つのSuperpixelのピクセル数の差を画像のピクセル数で割ったもの はSuperpixelのピクセル数 以上より，matching degree matrix が以下のように定式化される はそれぞれ0.2, 0.05とした． 以上より，が下のように定式化される． Flow generation をもとに二方向の最終的なフローを導き出す．ここでは前者しか示さないが，後者も同様にできる．まず，とみなす．次に重心の変位を求める．そして局所変形を以下の変分最適化(variational optimization)で求める． はそれぞれ色で画像をマスクする行列 はピクセルの位置を受け取ってそこのフローを返すの関数 上式でマスクと変位の一致度合いを計算し，下式で変位の滑らかさを表していると思われる また，外れ値を取り除くため，となるようななどは取り除く． 4.2 Recurrent Flow Refinement Network RFNの構成 これを入れるモチベは２つ 頑健でないフローは前段で排除されてしまっているが，このネットワークでそこにも頑健なフローを作れる 前段は大きなフローの検出に役立つが，細かい動きや複雑な動きには不適切 ※からを作るプロセスのみ示す まずから各ピクセルの信頼度を計算する3層CNNに通しを得る，にをかけてマスクしたものを初期値とする． これとをConvGRUに入れて残差が計算される．これを現在のフローに足すということを繰り返す． 4.3 Frame Warping and Synthesis 得られた最終的なフローとSoft-splatの手法を使ってSplattingと合成をする． 最終的にGridNetで画像を合成する． 4.3 Learning trainingの損失関数はGroundTruthと出力画像のL1Lossを採用し，訓練の際には2つのフェーズに分けた． Training phase … RFRをRAFTと同様に訓練し，残りの部分を訓練するためにRFRの重みを調整して実世界のデータセット(Quadratic video interpolationを参照のこと)で200epoch訓練した． SGMモジュールは使っていない． 訓練率は1e-4で，100, 150エポック時に0.1倍した． Fine-tuning phase …ATD-12Kを使ってシステム全体を50epoch訓練． 訓練率 1e-6． 画像は960540にリスケールされ，380380の画像にランダムに切り取られる． バッチサイズは16． オーグメンテーションのために画像を裏返したり三つ組みを逆順にしたりした． 5. Experiments AnimeInterpを最近のSOTAの手法 (Super SloMo, DAIN, QVI, AdaCoF, SoftSplat)と比較した．SoftSplatについては既存の実装がなかったため論文をもとに実装し，AnimeInterpと同じ手法で訓練した． Fine-tuningのデータセットはATD-12Kを使用し，Finetuning前後で別々に評価した． 3つ組のうち真ん中の画像を予測するという手法でGTと予測画像の間のPSNR, SSIMを評価値とした．評価は画像全体(Whole), 興味領域(RoI)に対して行った．また，レベル別の評価も行った． 5.1 Comparative Evaluation Quantitative Evaluation (定量的評価) 定量的評価の結果．全カテゴリでAnimeInterpの精度が高くなっていることがわかる． 全評価値で優っていた．RoIでも優っていたので，より大きな動きを反映できているといえる． Qualitative Evaluation (定性的評価) 各手法の出力画像とそのオプティカルフロー． 難しい例でも比較的よく予測できていることがわかる． 同じ色が重なり合う上に局所的に不連続で大きな動きのある画像の例．上の画像の場合，両手が重なり，その変位も大きい．いずれの手法も輪郭がぼやけてしまっているが，AnimeInterpは比較的もとの形を保っているように見える． 背景とキャラクターが逆方向に大きく動く例．下の画像の場合，背景は大きく下に動いており，人物は逆方向に動いている．AnimeInterp以外の手法は背景の動きに引っ張られて人物もその方向に動いてしまっていることが確認されるが，AnimeInterpは人物の形を認識し，分離できていることがわかる． 5.2 Ablation Study Ablation studyの結果．SGM, RFRがそれぞれ重要な役割をになっていることがわかる． Quantitative Evaluation SGM, RFRをそれぞれ抜いたモデルでも評価してみた(a)． どれかを抜くとPSNRは低下するが，RFRを抜いた時のほうが大きく下がった．RFRなしではフローが粗く，双方向のフローが合わない部分はフローが0になるからである． SGMがないときの差はEasyよりもHardのほうが大きい．つまり大きな動きに対して効果があることがわかる． Qualitative Evaluation SGMの有無で出力画像を見てみる(b)． SGMがないときは局所最適値にはまるためフローが不正確になる．例5では右手が大きく動いて次のフレームで左手の近くまで行っているため，SGMなしでは2フレーム目の右手を左手と勘違いしている．SGMはGlobal context matchingでこれを防いでいる 5.3 Further Analysis Influence of Difficulty Levels and Motion RoIs アニメにおける映像補完の問題に対処していないモデルは特に難易度が上がるとPSNRスコアが大きく落ちる 様々な手法でRoI部分での性能が落ちるので，そこの修復に注目したさらなる研究が期待される． User Study User studyの結果．他の3手法に比べ，提案手法のほうが良いと答えた人がいずれも8割程度いた． 10人の人間にそれぞれ提案手法と既存手法で生成されたもののうち150の3つ組を見せ，どちらが良いかを主観的に判断してもらったところ，いずれの手法に対しても約8:2で提案手法のほうがよいという結果が得られた． 感想 実際に使ってみたり，デモ動画を見てみますと，確かに自然に補完された動画になっていることがわかります．ただ，補完されたフレームを１つずつ確認しますと，輪郭がはっきりしていなかったり，大きく動いているオブジェクトが正しく描画されていなかったりと，商用利用は難しいのではないかと思わせられる点もあります． ATD-12Kデータセット内の画像．この２つのフレームの間を予測する． 訓練済みモデルの出力(左)とGTの画像(右)．出力が大きく崩れている． 上の画像はATD12-Kに含まれる画像とそれを入力した際の出力結果ですが，1フレーム目で隠れていた自動車のバンパー部分がほとんど構成できていません．このように，一方のフレームで大きなオクルージョンが発生している場合は，SGMでフローの構成をできず，RFRでの補填もあまりうまくいかないため，お粗末な結果になってしまうようです． ただ，元のフレーム数がそれなりに多ければ，このようなフレームが入っていても動画としてみる分にはあまり気にならないため，実用的な素晴らしい研究だと思います． 注釈 Trapped-ball algorithm Vectorizing Cartoon Animationsで提唱された，不連続な輪郭で区切られた領域を調べるアルゴリズム． 元論文より引用 まず領域を塗りつぶす (b) 一色で塗られた領域に円の構造物を配置する(trapped-ball) それが動ける領域を調べる (d) その領域を広げる 以上を塗りつぶされた領域がなくなるまで行う．半径は少しずつ小さくする Superpixel .center{ display:flex; justify-content: center; } ATD-12Kデータセット内の画像(左)とそのSuperpixel-segmentationの結果(→) 画像の中で色合いの似ている範囲をまとめた領域． これのセグメンテーションを行うことをSuperpixel-segmentationとよぶ Superpixel pooling Superpixelをプーリングのレイアウトとして使うこと．今までのプーリングは一般的に正方形だったのをこのSuperpixelの部分でプーリングすることだと考えられる．Superpixel pooling層を通すと，の行列が出てくる．はSuperpixelの数，は特徴量の数 Variational optimization 微分不可能，あるいは不連続な関数の最大化を行う手法で，最大値の下限が期待値であることを利用して，パラメータにより期待値を最大化することにより最大値に近づける手法． Convolutional GRU 畳み込み＋再帰ネットワークで時空間の関係性をとらえられるようになり，画像列の動きの情報を抽出できるようになったネットワーク．","link":"/2022/09/03/papers/AnimeInterp/"}],"tags":[{"name":"大学","slug":"大学","link":"/tags/%E5%A4%A7%E5%AD%A6/"},{"name":"CPU実験","slug":"CPU実験","link":"/tags/CPU%E5%AE%9F%E9%A8%93/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"GIS","slug":"GIS","link":"/tags/GIS/"},{"name":"OSMnx","slug":"OSMnx","link":"/tags/OSMnx/"},{"name":"Folium","slug":"Folium","link":"/tags/Folium/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"深層学習","slug":"深層学習","link":"/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/"},{"name":"備忘録","slug":"備忘録","link":"/tags/%E5%82%99%E5%BF%98%E9%8C%B2/"},{"name":"Blender","slug":"Blender","link":"/tags/Blender/"},{"name":"Katex","slug":"Katex","link":"/tags/Katex/"},{"name":"Joplin","slug":"Joplin","link":"/tags/Joplin/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"Marp","slug":"Marp","link":"/tags/Marp/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"},{"name":"GithubPages","slug":"GithubPages","link":"/tags/GithubPages/"},{"name":"Google","slug":"Google","link":"/tags/Google/"},{"name":"Tex","slug":"Tex","link":"/tags/Tex/"},{"name":"遊び","slug":"遊び","link":"/tags/%E9%81%8A%E3%81%B3/"},{"name":"BrainF*ck","slug":"BrainF-ck","link":"/tags/BrainF-ck/"},{"name":"ツール","slug":"ツール","link":"/tags/%E3%83%84%E3%83%BC%E3%83%AB/"},{"name":"画像処理","slug":"画像処理","link":"/tags/%E7%94%BB%E5%83%8F%E5%87%A6%E7%90%86/"},{"name":"論文","slug":"論文","link":"/tags/%E8%AB%96%E6%96%87/"}],"categories":[{"name":"大学","slug":"大学","link":"/categories/%E5%A4%A7%E5%AD%A6/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"開発","slug":"開発","link":"/categories/%E9%96%8B%E7%99%BA/"},{"name":"Blender","slug":"Blender","link":"/categories/Blender/"},{"name":"備忘録","slug":"備忘録","link":"/categories/%E5%82%99%E5%BF%98%E9%8C%B2/"},{"name":"遊び","slug":"遊び","link":"/categories/%E9%81%8A%E3%81%B3/"},{"name":"ツール","slug":"ツール","link":"/categories/%E3%83%84%E3%83%BC%E3%83%AB/"},{"name":"論文","slug":"論文","link":"/categories/%E8%AB%96%E6%96%87/"}]}